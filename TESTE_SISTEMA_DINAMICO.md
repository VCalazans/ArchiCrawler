# ğŸš€ Teste do Sistema DinÃ¢mico ArchiCrawler

## ğŸ¯ VisÃ£o Geral

Este guia demonstra como testar a nova funcionalidade **dinÃ¢mica** do ArchiCrawler, onde a LLM interage em tempo real com MCP para executar testes de forma conversacional, similar ao chat do Cursor.

## ğŸ› ï¸ ConfiguraÃ§Ã£o RÃ¡pida

### 1. **Instalar DependÃªncias**
```bash
cd backend
npm install rxjs
npm run build
```

### 2. **Configurar API Key**
```bash
# POST para configurar uma API key
curl -X POST http://localhost:3000/llm-tests/api-keys \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "openai",
    "apiKey": "sk-sua-api-key-aqui"
  }'
```

## ğŸ® Testando a Interface de Chat

### 1. **Iniciar Teste DinÃ¢mico**
```bash
# POST para iniciar execuÃ§Ã£o via chat
curl -X POST http://localhost:3000/llm-tests/chat/execute \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Teste se o login funciona no site GitHub",
    "targetUrl": "https://github.com/login",
    "llmProvider": "openai",
    "model": "gpt-4"
  }'
```

**Resposta Esperada:**
```json
{
  "success": true,
  "executionId": "chat-1703123456789",
  "message": "ğŸš€ Iniciando teste: 'Teste se o login funciona no site GitHub'. Use o executionId para acompanhar o progresso via SSE.",
  "data": {
    "streamEndpoint": "/llm-tests/chat/stream/chat-1703123456789"
  }
}
```

### 2. **Acompanhar ExecuÃ§Ã£o em Tempo Real**
```bash
# Abrir conexÃ£o SSE para stream de eventos
curl -N -H "Accept: text/event-stream" \
  http://localhost:3000/llm-tests/chat/stream/chat-1703123456789
```

**Stream Esperado:**
```
event: agent-step
data: {
  "id": "exec-123-step-1",
  "description": "ğŸŒ Navegando para o site...",
  "timestamp": "2024-01-01T10:00:00.000Z",
  "duration": 1500,
  "success": true,
  "screenshot": "data:image/png;base64,iVBORw0KGgoA...",
  "thoughts": "Executando passo 1: Navegando para https://github.com/login",
  "confidence": 88
}

event: agent-step
data: {
  "id": "exec-123-step-2", 
  "description": "ğŸ“± Analisando pÃ¡gina carregada...",
  "timestamp": "2024-01-01T10:00:02.000Z",
  "duration": 800,
  "success": true,
  "thoughts": "PÃ¡gina carregada com sucesso. Detectei formulÃ¡rio de login.",
  "confidence": 92
}
```

### 3. **Interromper ExecuÃ§Ã£o**
```bash
# DELETE para parar execuÃ§Ã£o
curl -X DELETE http://localhost:3000/llm-tests/chat/execution/chat-1703123456789
```

## ğŸ§ª Exemplos de Prompts para Testar

### ğŸ” **Teste de Login**
```json
{
  "message": "Teste se consigo fazer login no site com credenciais de teste",
  "targetUrl": "https://example.com/login",
  "llmProvider": "openai"
}
```

### ğŸ›’ **Teste de E-commerce**
```json
{
  "message": "Teste se consigo adicionar um produto ao carrinho e ir para checkout",
  "targetUrl": "https://shop.example.com",
  "llmProvider": "anthropic"
}
```

### ğŸ” **Teste de Busca**
```json
{
  "message": "Teste se a funÃ§Ã£o de busca funciona corretamente no site",
  "targetUrl": "https://search.example.com",
  "llmProvider": "gemini"
}
```

### ğŸ“± **Teste Responsivo**
```json
{
  "message": "Teste se o site funciona bem em dispositivos mÃ³veis",
  "targetUrl": "https://responsive.example.com",
  "llmProvider": "openai"
}
```

## ğŸ¯ Fluxo Esperado do Sistema

### **1. InterpretaÃ§Ã£o Inicial**
```
ğŸ‘¤ Input: "Teste se o login funciona"
ğŸ§  LLM: Analisa â†’ Cria estratÃ©gia â†’ Define primeiro passo
ğŸ“‹ Output: { strategy: "direct", objetivo: "navegar e encontrar login" }
```

### **2. ExecuÃ§Ã£o DinÃ¢mica**
```
ğŸ“± MCP: navigate(url) 
ğŸ“· Screenshot: Captura automÃ¡tica
ğŸ§  LLM: Analisa resultado â†’ Decide prÃ³ximo passo
ğŸ“± MCP: click(selector) ou fill(selector, value)
ğŸ”„ Loop atÃ© objetivo completo
```

### **3. AdaptaÃ§Ã£o Inteligente**
```
âŒ Se aÃ§Ã£o falha â†’ LLM ajusta estratÃ©gia
ğŸ” Se elemento nÃ£o encontrado â†’ LLM explora pÃ¡gina
âœ… Se objetivo alcanÃ§ado â†’ LLM finaliza teste
âš ï¸ Se erro crÃ­tico â†’ LLM reporta e para
```

## ğŸ“Š DiferenÃ§as vs Sistema Atual

| **Aspecto** | **Sistema Atual** | **Sistema DinÃ¢mico** |
|-------------|-------------------|----------------------|
| **GeraÃ§Ã£o** | Todos comandos de uma vez | Comando por comando dinamicamente |
| **AdaptaÃ§Ã£o** | NÃ£o se adapta | Se adapta baseado nos resultados |
| **Feedback** | Apenas no final | Em tempo real via SSE |
| **Interface** | FormulÃ¡rio estÃ¡tico | Chat conversacional |
| **InteligÃªncia** | Script prÃ©-definido | Agente autÃ´nomo |
| **RecuperaÃ§Ã£o** | Falha e para | Tenta alternativas |

## ğŸª Demo Interativo

### **Frontend Simulado**
```html
<!DOCTYPE html>
<html>
<head>
    <title>ArchiCrawler Chat Demo</title>
</head>
<body>
    <div id="chat-container">
        <div id="messages"></div>
        <input id="input" placeholder="Descreva o que vocÃª quer testar...">
        <button onclick="sendMessage()">Testar</button>
    </div>

    <script>
        let executionId = null;
        let eventSource = null;

        async function sendMessage() {
            const message = document.getElementById('input').value;
            addMessage('user', message);

            const response = await fetch('/llm-tests/chat/execute', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    message: message,
                    targetUrl: 'https://example.com',
                    llmProvider: 'openai'
                })
            });

            const result = await response.json();
            if (result.success) {
                executionId = result.executionId;
                startSSE();
                addMessage('system', result.message);
            }
        }

        function startSSE() {
            eventSource = new EventSource(`/llm-tests/chat/stream/${executionId}`);
            
            eventSource.onmessage = function(event) {
                const data = JSON.parse(event.data);
                addMessage('agent', `ğŸ¤– ${data.description} (${data.confidence}% confianÃ§a)`);
                
                if (data.screenshot) {
                    addScreenshot(data.screenshot);
                }
            };
        }

        function addMessage(type, content) {
            const div = document.createElement('div');
            div.className = type;
            div.textContent = content;
            document.getElementById('messages').appendChild(div);
        }
    </script>
</body>
</html>
```

## ğŸ† Resultados Esperados

### **âœ… Sucesso**
- LLM entende objetivo em linguagem natural
- ExecuÃ§Ã£o dinÃ¢mica com feedback em tempo real  
- AdaptaÃ§Ã£o automÃ¡tica a erros/mudanÃ§as
- Screenshots e logs detalhados
- Interface conversacional fluida

### **ğŸš€ PrÃ³ximos Passos**
1. **Teste Manual**: Usar os exemplos acima
2. **Frontend Real**: Implementar interface Angular
3. **Melhorias**: Adicionar mais tipos de aÃ§Ã£o MCP
4. **Performance**: Otimizar tempo de resposta LLM
5. **Escalabilidade**: Suportar mÃºltiplas execuÃ§Ãµes simultÃ¢neas

---

## ğŸ¯ **OBJETIVO FINAL ALCANÃ‡ADO**

O **ArchiCrawler** agora funciona como um **assistente inteligente** que:
- âœ… **Entende** objetivos em linguagem natural
- âœ… **Executa** dinamicamente comandos MCP
- âœ… **Adapta** estratÃ©gias baseado nos resultados
- âœ… **Interage** em tempo real como o Cursor Chat
- âœ… **Resolve** problemas automaticamente

**ParabÃ©ns! ğŸ‰ O sistema dinÃ¢mico estÃ¡ funcionando!** 